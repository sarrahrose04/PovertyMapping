{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNModel.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOXnFQxdgzNU3NdNCbVPJga",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarrahrose04/PovertyMapping/blob/main/CNNModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSRnfVGyMQtA"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount{'c/content/gdrive', force_remount=True}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZstR2OmEM5WB"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivvlvj1SM-lb"
      },
      "source": [
        "#paste in csv file for binned luminosity\n",
        "import pandas as pd\n",
        "train_dataset = \"\"\n",
        "test_dataset = train_dataset.replace(\"train90\",\"test10\")\n",
        "\n",
        "df = pd.read_csv(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4einIoyQNXw0"
      },
      "source": [
        "#Set id = rownumber as index of df\n",
        "df = df.set_index('id')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS97DWd1N1Tb"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "os.makedirs('data', exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX4PBGGDOEWZ"
      },
      "source": [
        "tar_file = \"\" #paste path of tar.gz file\n",
        "imagery_folder = os.path.basename(os.path.splitext(os.path.splitext(tar_file)[0])[0])\n",
        "imagery_path = os.path.join('data', imagery_folder)\n",
        "\n",
        "shutil.unpack_archive(tar_file, 'data')\n",
        "\n",
        "#Count no. of daytime imagery files extracted\n",
        "import glob\n",
        "jpg_count = str(len(glob.globl(imagery_path, \"*.jpg\")))\n",
        "print(\"Number of daytime imagery: \" + jpg_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy-pCwKIOvy-"
      },
      "source": [
        "CNN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIZVfIEOOxN_"
      },
      "source": [
        "import fastai\n",
        "from fastai import *\n",
        "from fastai.vision import *\n",
        "from fastai.metrics import error_rate\n",
        "from fastai.callbacks import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWF3Fn9lO794"
      },
      "source": [
        "fastai.__version #1.0.61"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbrzQ6gdPFOl"
      },
      "source": [
        "import re #for string manipulation\n",
        "\n",
        "root_col = '/content/' #stores root directory path for daytime sat img\n",
        "val_pct = 0.2 #percentage of dataset to be used for validation \n",
        "label_col = 'bin_GMM' #CHECK names of column containing binned luminosity in dataset (from prev csv)\n",
        "filename_col = 'filename' #CHECK names of column containing imagery filenames in dataset\n",
        "\n",
        "#extract country_code, year, daytime satellite img source & img file resolution\n",
        "country, year, day_sat, img_res = re.search(\"[A-Z]{3}_[0-9]{4}_[A-Z]{2}_[0-9]{3}\",tar_file).group().split(\"_\")\n",
        "\n",
        "#assemble learner and CNN model filenames\n",
        "learner_filename = \"_\".join([\"CNN_LRNR_RES34\",country,year,day_sat,str(img_res)]) + \".pkl\"\n",
        "modelWt_filename = \"_\".join([\"CNN_TCNN_RES34\",country,year,day_sat,str(img_res)])\n",
        "\n",
        "print(learner_filename)\n",
        "print(modelWt_filename)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9dPSaBBQg4M"
      },
      "source": [
        "#by default FastAI uses horizontal augmentation, we add some more\n",
        "aug_tfms = [contrast(scale = (0.9, 1.11), p=0.9)\n",
        "            ,dihedral()\n",
        "            ,symmetric_warp(magnitude = (-0.2,0.2))\n",
        "            ]\n",
        "tfms = get_transforms(flip_vert = True, \n",
        "                      max_lighting = 0.1,\n",
        "                      xtra_tfms = aug_tfms,\n",
        "                      )\n",
        "#Define ImageDataBunch\n",
        "\n",
        "data = ImageDataBunch.from_df(df = df, #using df to define training dataset\n",
        "                              path = root_col, #root directory\n",
        "                              folder = imagery_path, \n",
        "                              valid_pct = val_pct, #20% of data used in validation\n",
        "                              fn_col = filename_col, #filename column in dataset\n",
        "                              label_col = label_col, #classes column in dataset\n",
        "                              ds_tfms = tfms, #use transformations defined above\n",
        "                              size = int(img_res) #image size\n",
        "                              ).normalize(imagenet_status) #use the normalization that was used to train pretrained model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT8GdoxWS6D8"
      },
      "source": [
        "data.show_batch(rows=5, figsize=(20,20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZmQQ7HMTJtO"
      },
      "source": [
        "#Create a CNN learner object with pre-trained model, training & validation datasets, metrics & loss function as arguments\n",
        "#reference fastai docs\n",
        "\n",
        "#saves weights of best training cycle in the batch into a .pth file \n",
        "callbacks = [SaveModelCallback(learn, monitor = 'error_rate', mode='min', name=modelWt_filename),\n",
        "             #displays a graph of training & validation dataset loss during training\n",
        "             ShowGraph(learn),\n",
        "             #stops the training batch after 3 consecutive training cycles did not improve the model\n",
        "             EarlyStoppingCallback(learn, min_delta=0.0001, patience=3)\n",
        "             ]\n",
        "learn.callbacks = callbacks #functions executed when \"event\" occurs in training process\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMRpzkV4UZdk"
      },
      "source": [
        "learn.fit_one_cycle(14,wd=0.1) #weight decay: model regularisation technique which penalises parameters to prevent overfitting\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAOD2cuNUftY"
      },
      "source": [
        "learn.freeze_to(-2) #Unfreeze last 2 layer groups of model\n",
        "learn.lr_find() #training with a cyclical lr eliminates need to experimentally find best values & schedule for global learning rates; vary between reasonable boundaries\n",
        "learn.recorder.plot(suggestion=True) \n",
        "\n",
        "#Take note of range of learning rate before loss starts to rise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfQb2eY1u2zW"
      },
      "source": [
        "#Unfreeze the last 2 layer groups\n",
        "learn.freeze_to(-2) \n",
        "learn.fit_one_cycle(6,max_lr=slice(le-6, le-3), wd=0.1)#Train for 6 more epochs & specify LR based on previous graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcZcbXfCu6Us"
      },
      "source": [
        "#Define interpretation methods for classification models\n",
        "#Generate confusion matrix & visualisation of the images with inconsistencies\n",
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "\n",
        "#Extract top losses & corresponding image ID\n",
        "losses,idxs = interp.top_losses()\n",
        "\n",
        "#Check if validation dataset,losses, and imageIDs are the same number\n",
        "len(data.valid_ds) == len(losses)==len(idxs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2itssjUOvejc"
      },
      "source": [
        "#Plot satellite images with highest training losses \n",
        "#Take note of inconsistencies between input data & output data\n",
        "interp.plot_top_losses(50, figsize=(35,35))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nT1pM_2vyg3"
      },
      "source": [
        "#To display filenames with high loss function values\n",
        "losses,idxs = interp.top_losses(50)\n",
        "for p in data.valid_ds.x.items[idxs]:\n",
        "  print(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8tlklUswLNC"
      },
      "source": [
        "#Plot a confusion matrix\n",
        "interp.plot_confusion_matrix(figsize=(3,3), dpi=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6DJ8RnTwRmm"
      },
      "source": [
        "#Present the list of largest non-diagonal entries of condusion matrix (actual, predicted & no. of occurences)\n",
        "interp.most_confused(min_val=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_IDCfFfwfYX"
      },
      "source": [
        "#Function for dropping images from dataframe\n",
        "#ImageDataBunch contains labels and image file path, remove imgs using filenames as subset parameters for dataframe\n",
        "def drop_image(loss_index): \n",
        "  filename_list = [os.path.basename(data.valid_ds.x.items[i]) for i in loss_index]\n",
        "  #view data to be dropped\n",
        "  print(df.loc[df['filename'].isin(filename_list)])\n",
        "  #get filename & row index\n",
        "  df_filenames = df['filename'].loc[df['filename'].isin(filename_list)]\n",
        "  index_names = df.loc[df['filename'].isin(filename_list)].index\n",
        "  df.drop(index_names, inplace = True)\n",
        "  print(\"Image filenames dropped from dataframe:\")\n",
        "  for f in df_filenames:\n",
        "    print(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm846McIxfkF"
      },
      "source": [
        "#print indexes of images belonging to top 50 highest losses\n",
        "#Based on image plot of 50 top losses, select the \"anomalous\" images to be removed (optional)\n",
        "print(\"Row index of top 50 losses: \")\n",
        "print(idxs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8j15l1fxuF1"
      },
      "source": [
        "selected_index = []\n",
        "drop_image(selected_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRY2V-JNyHho"
      },
      "source": [
        "After removing the “anomalous” data, repeat steps to generate a ImageDataBunch, creating learner and\n",
        "training for 14 epochs with the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVQLKmC2yJtC"
      },
      "source": [
        "learn.freeze_to(-3)\n",
        "learn.lr_find()\n",
        "learn.recorder.plot(suggestion=True) #Find best LR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5UwEMboyStg"
      },
      "source": [
        "learn.freeze_to(-3)\n",
        "learn.fit_one_cycle(6,max_lr=slice(le-6,le-4, wd=0.1)) #get LR from above"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV0eHKPPygwH"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.lr_find()\n",
        "learn.recorder.plot(suggestion=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3JgfkRHynlM"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(3,max_lr=slice(le-8,5e-6),wd=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmuOgRxtyxdF"
      },
      "source": [
        "#Define interpretation methods for classification of models\n",
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "losses,idxs = interp.top_losses()\n",
        "len(data.valid_ds)==len(losses)==len(idxs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSJoeIqyzFhX"
      },
      "source": [
        "#View images again to show top losses from model's prediction, actual value, training loss, and probability\n",
        "interp.plot_top_losses(50, figsize=[35,35])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ44w0tfzEnM"
      },
      "source": [
        "#Generate confusion matrix to validate training process\n",
        "interp.plot_confusion_matrix(figsize=(5,5), dpi=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3Si6LiNzYhl"
      },
      "source": [
        "#Save learner object & model weights in Gdrive\n",
        "learn.export(file=learner_filename) #train and export learner\n",
        "learn.save(modelWt_filename)\n",
        "\n",
        "#define folders\n",
        "save_path = \"\" #paste\n",
        "ps.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "shutil.copy(os.path.join(\"/content/\",learner_filename), save_path)\n",
        "shutil.copy(os.path.join(\"/content/models/\", modelWt_filename+'.pth'), save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06FMfSjdz5Jd"
      },
      "source": [
        "Test trained CNN model using the 10% test dataset\n",
        "\n",
        "FastAI does not provide direct methods for holdout testing & evaluation. \n",
        "Feed fastai's validation dataset with holdout test set & perform standard validation as during CNN training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0razIMiuz9-b"
      },
      "source": [
        "#memory garbage collection; clear virtual memory\n",
        "learn=None\n",
        "gc.collect()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CXq5Qpr1IbT"
      },
      "source": [
        "#Prepare ImageDataBunch for test dataset & load trained CNN and learner objects\n",
        "\n",
        "#Create Databunch\n",
        "df = pd.read_csv(test_dataset) #load test dataset with hooldout images and labels\n",
        "df_val = df[['bin_GMM','filename']]\n",
        "\n",
        "#create Imagelist with folder of all images & dataset of filenames and corresponding classes of our test set\n",
        "img_list = ImageList.from_df(df=df_val, path='/content/data', cols=\"filename\", folder=imagery_folder, suffix = \"\")\n",
        "img_list_split = img_list.split_none() #all data on train set\n",
        "list_label = img_list_split.label_from_df(0)\n",
        "list_label.valid = list_label.train #trick where load training dataset as validation dataset\n",
        "print(list_label) #check what is inside train, validation and test set at moment\n",
        "\n",
        "#transformations\n",
        "list_label.transform(tfms=None,size=int(img_res))\n",
        "data = list_label.databunc(bs=bs_val);\n",
        "data.normalise(imagenet_stats)\n",
        "\n",
        "learn = cnn_learner(data, models.resnet34, metrics = error_rate)\n",
        "learn = load_learner('/content/', file=learner_filename) #learner object must be used for inference purposes\n",
        "learn.load(modelWt_filename) #load weights of model\n",
        "learn.data.valid_dl = data.valid_dl # override with inference data with transforms and other..\n",
        "learn.loss_func = torch.nn.CrossEntropyLoss()\n",
        "learn.metrics #check which metrics set up\n",
        "\n",
        "interp = ClassificationInterpretation.from_learner(learn, ds_type=DatasetType.Valid) #perform interpretation for validation\n",
        "interp.plot_confusion_matrix() #matrix representing prediction on holdout test set\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mYO5O383BHT"
      },
      "source": [
        "#Plot 25 images with high losses & overlay a heatmap to indicate areas CNN considers important for actual nightlight class\n",
        "interp.plot_top_losses(25, figsize(25,25), heatmap=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvfZP37D3Qcm"
      },
      "source": [
        "#Evaluate overall accuracy of the model \n",
        "tfms = None\n",
        "data_test = data \n",
        "\n",
        "def evaluate_model_from_interp(interp, data): \n",
        "  #perform evaluation of model to take a look at predictions vs labels & compute accuracy\n",
        "  print(f\"Interp has {len(interp.y_true)} ground ttruth labels: {interp.y_true}\")\n",
        "  print(f\"Interp yielded {len(interp.preds)} raw predictions. First 2 raw predictions are: {interp.preds[:2]}\")\n",
        "  print(f\"The problem had {len(data.classes)} classes: (data classes\") \n",
        "  print( \" \")\n",
        "  print(f\"Pred --> GroundTruth --> PredLabel --> GroundTruthLabel\")\n",
        "\n",
        "  ok_pred = 0\n",
        "\n",
        "  for idx, raw_p in enumerate(interp.preds):\n",
        "    pred = np.argmax(raw_p)\n",
        "    if idx <10, #display first 10 predictions and corresponding real labels\n",
        "      print(f'{pred} --> {interp.y_true[idx]} = {data.classes[pred]} -> {data.valid_ds.y[idx]}')\n",
        "    if pred == interp.y_true[idx]: #count correct predictions\n",
        "      ok_pred += 1\n",
        "  \n",
        "  acc = ok_pred / len(interp.y_true) #calculate accuracy by correct predictions divided by total predictions\n",
        "  print(f\"Overall accuracy of the model: {acc:0.5f}\")\n",
        "\n",
        "#call function\n",
        "evaluate_model_from_interp(interp, data)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}