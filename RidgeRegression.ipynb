{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RidgeRegression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNGNorby/bvOsUa8yZUYS/c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarrahrose04/PovertyMapping/blob/main/RidgeRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY72a4U7HwUG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount{'c/content/gdrive', force_remount=True}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD7O_p_6H4Q5"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20tq6HJvH-sH"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "CENI_full_file = \" \"#paste link to dataset containing binned luminosity & poverty rates\n",
        "dr_raw = pd.read_csv(CENI_full_file)\n",
        "df_raw.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjM_HwCYISTl"
      },
      "source": [
        "#Define parameters needed for model \n",
        "\n",
        "import re\n",
        "import os\n",
        "\n",
        "#extract country code, year, daytime satellite imagery source & imagery file resolution from tar filename\n",
        "country, year, day_sat, img_res = re.search(\"[A-Z]{3}_[0-9]{4}_[A-Z]{2}_[0-9]{3}\",CENI_full_file).group().split(\"_\")\n",
        "\n",
        "target_variable_name = \"POV_\"+year\n",
        "df_full = df.raw.copy()\n",
        "\n",
        "#print if the necessary columns are defined correctly\n",
        "print(df_full[[\"geocode\",target_variable_name]])\n",
        "print(df_full.shape)\n",
        "print(df_full.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5fR41_JJB0r"
      },
      "source": [
        "df_full = df_full.dropna()\n",
        "df_full.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NskDAmtJGGJ"
      },
      "source": [
        "#Define features filename\n",
        "features_filename = \"_\".join([\"CNN_FOUT_RES34\",country,year,day_sat,str(img_res)])+\".csv\"\n",
        "\n",
        "#Load into python as df\n",
        "features_raw = pd.read_csv(os.path.join(os.path.dirname(CENI_full_file), features_filename))\n",
        "print(features_raw.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvB7F4y1JuAB"
      },
      "source": [
        "#Compare filenames of daytime satellite imagery processed during feature extraction with filename list from original csv\n",
        "all_img = features_raw[\"filename\"]\n",
        "\n",
        "missing_images_ID = df_full[\"filename\"].isin(all_img)\n",
        "missing_csventry_ID = all_img.isin(df_full[\"filename\"])\n",
        "\n",
        "missing_images = df_full(-missing_images_ID)\n",
        "missing_entries = all_img[-missing_csventry_ID]\n",
        "print*\"images in the df_full, but not in the features file: \")\n",
        "print(missing_images)\n",
        "\n",
        "print(\"_________________\")\n",
        "print(\" \")\n",
        "print(\"images in the features file, but not in the df_full: \")\n",
        "print(missing_entries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2lW-pxRMzjT"
      },
      "source": [
        "#Delete all rows in original CSV file that contain filenames that were not processed during feature extraction\n",
        "df = df_full.copy(deep = True)[missing_images_ID]\n",
        "print(df_full.shape)\n",
        "print(df.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJM64VhtNARz"
      },
      "source": [
        "#Make a temporary file that only contains the filename & geocode columns\n",
        "img_geocode = df[[\"filename\", \"geocode\"]]\n",
        "#drop the double rows we just want the relation between image and geocode\n",
        "img_geocode = img_geocode.drop_duplicates()\n",
        "\n",
        "img_geocode.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZRszk7pNWCL"
      },
      "source": [
        "#Generate a new df containing only training poverty data\n",
        "df_LHS = df[['geocode', 'data_split', target_variable_name]]\n",
        "df_LHS = df.LHS.drop_duplicates(subset='geocode')\n",
        "print(df_LHS.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3DiqiR-NjV6"
      },
      "source": [
        "#Merge geocode filename dataframe with features dataframe\n",
        "#Ensure that datatypes align \n",
        "img_geocode.filename.astype(str)\n",
        "features_raw.filename.astype(str)\n",
        "#merge\n",
        "featrues = img_geocode.merge(features_raw, on = \"filename\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y5dDSJhNzx8"
      },
      "source": [
        "#Compute avg features by geocode grp & generate 1 feature vector per geocode\n",
        "avg_features = features.copy(deep = True)\n",
        "avg_features.drop(columns=['filename'])\n",
        "avg_features = avg_features.groupby('geocode', as_index=False).mean()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcq-5leBOLw8"
      },
      "source": [
        "#Merge training poverty & averaged features dataframes\n",
        "\n",
        "avg_features_full = df_LHS.merge(avg_features, on = 'geocode')\n",
        "\n",
        "print(df_LHS.shape)\n",
        "print(avg_features.shape)\n",
        "print(avg_features_full.shape)\n",
        "print(avg_features_full.iloc[:5,:6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHcgfd46OcM-"
      },
      "source": [
        "#Load packages needed to perform ridge regression \n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Ridge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLjZX5BSsWfi"
      },
      "source": [
        "import numpy as np\n",
        "outlier_flag = 4 #standard deviation\n",
        "validation_size_percent = 10\n",
        "\n",
        "#Determine geocodes of outliers from avged features based on the defined standard deviation\n",
        "#specified in variable outlier flag\n",
        "outliers = avg_features_full['geocode'][avg_features_full['target_variable_name']>avg_features_full[target_variable_name].mean() +\n",
        "                                        outlier_flag * avg_features_full[target_variable_name].std()].unique()\n",
        "\n",
        "print(\"outlier Region: \")\n",
        "print(outliers)\n",
        "print(\"number of outliers: \" + str(len(outliers)))\n",
        "\n",
        "#Extract valisation datasets & drop outliers\n",
        "validation_regions = avg_features_full['geocode'][avg_features_full['data_split'] == (validation_size_percent/100)].unique()\n",
        "print(\"number of validation_regions: \"+str(len(validation_regions)))\n",
        "\n",
        "#combine validation and outlier regions to drop them at once\n",
        "drop_regions = np.append(outliers, validation_regions)\n",
        "\n",
        "#drop outliers and validation set\n",
        "avg_features = avg_features_full[~avg_features_full['geocode'].isin(drop_regions)]\n",
        "avg_features_validation = avg_features_full[avg_features_full['geocode'].isin(validation_regions)]\n",
        "\n",
        "#Create separate dataframes for full, training and test datasets\n",
        "\n",
        "#training set\n",
        "Xs = avg_features.drop(target_variable_name, 'geocode', 'data_split'], axis=1)\n",
        "y = avg_features[target_variable_name].values.reshape(-1,1)\n",
        "\n",
        "#full dataset \n",
        "Xs_full = avg_features_full.drop([target_variable_name, 'geocode', 'data_split'], axis=1)\n",
        "y_full = avg_features_full[target_variable_name].values.reshape(-1,1)\n",
        "\n",
        "#only validation set\n",
        "Xs_validation = avg_features_validation.drop([target]target_variable_name, 'geocode', 'data_split'], axis=1)\n",
        "y_validation = avg_features_validation[target_variable_name].values.reshape(-1,1)\n",
        "\n",
        "print(avg_features_full.shape)\n",
        "print(\"Xs shape: \"+str(Xs shape))\n",
        "print(\"y shape: \"+str(y.shape))\n",
        "print(\"Outlier flag: \"+str(outlier_flag) + \" sd\")\n",
        "print(\"Validation Xs shape: \")+str(Xs_Validation.shape))\n",
        "print(\"Validation relative size: \"+str(round( Xs_validation.shape[0] / avg_features_full.shape[0],2)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLzqVGImvrZY"
      },
      "source": [
        "#Set parameter space for lambda (ridge regression penalty term) that needs to be searched through\n",
        "max_lambda = 10\n",
        "print(\"maximum lambda: \" + str(max_lambda))\n",
        "min_lambda = 0.01\n",
        "print(\"minimum lambda: \"+str(min_lambda))\n",
        "\n",
        "parameters = {'alpha': 10**np.linspace(np.log10(min_lambda), np.log10(max_lambda), num = 15)}\n",
        "print (parameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf8W5iTrsWQk"
      },
      "source": [
        "#Perform Ridge Regression \n",
        "ridge = Ridge(fit_intercept = True, normalize=True)\n",
        "ridge_regressor = GridSearchCV(ridge, paramters, scoring = \"neg_mean_squared_error\")\n",
        "\n",
        "%time ridge_regressor.fit(Xs,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n4gHGBjxJMd"
      },
      "source": [
        "#Identify the model with the best CV score\n",
        "print(ridge_regressor.best_params_)\n",
        "best_ridge = ridge_regressor.best_estimator\n",
        "RSME_valid = round(((y_validation/100-0.01*best_ridge.predict(Xs_validation))**2).mean()**0.5,4)\n",
        "RSME_full = round((y_full/100-0.01*best_ridge.predict(Xs_full))**2).mean()**0.5,4)\n",
        "\n",
        "print(\"Validation RMSE: \") + str(RMSE_valid))\n",
        "print(\"FullRMSE: \"+str(RMSE_full))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4L-Y8A1zktN"
      },
      "source": [
        "#Define function for computing R-squared and root mean squared error\n",
        "\n",
        "import shutil \n",
        "\n",
        "def Ridge_Rsquared(predicted, true): \n",
        "  SSE = sum((predicted - true)**2)\n",
        "  SST = sum((true - true.mean())**2)\n",
        "  R_square = 1 - SSE / SST\n",
        "  RMSE = (SSE/len(true))**0.5\n",
        "  return round(float(R_square),4)\n",
        "\n",
        "#Implement calculations for training, validation & entire dataset\n",
        "eval_valid = Ridge_Rsquared(0.01*best_ridge.predict(Xs_validation), 0.01*y_validation)\n",
        "eval_full = Ridge_Rsquared(0.01*best_ridge.predict(Xs_full), 0.01*y_full)\n",
        "eval_train = Ridge_Rsquared(0.01*best_ridge.predict(Xs), 0.01*y)\n",
        "\n",
        "ridgestats = pd.DataFrame({\"stat\": ['RMSE_valid', \"RMSE_full\", \"R2_valid\", \"R2_full\", \"R2_train\"],\n",
        "                           \"value\": [RMSE_valid, RMSE_full, eval_valid, eval_full, eval_train]})\n",
        "print(ridgestats)\n",
        "\n",
        "#Generate regression statistics outputs as CSV file and copy in GDrive\n",
        "ridgestats_file = \"_\".join([\"CNN\", \"Ridgestats\", \"RES34\", country, year, day_sat, str(img_res)]) +\".csv\"\n",
        "ridgestats.to_csv(ridgestats_file)\n",
        "shutil.copy(os.path.join(\"/content/\", ridgestats_file), \"/content/gdrive/MyDrive\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L9Owjvk1QB_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#add functionality to plot at 45deg line\n",
        "def abline(slope, intercept):\n",
        "  \"\"\"Plot a line from slope & intercept\"\"\"\n",
        "  axes = plt.gca()\n",
        "  x_vals = np.array(axes.get_xlim())\n",
        "  y_vals = intercept + slope * x_vals\n",
        "  plt.plot(x_vals, y_vals, \"--\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qQEpi0u1ndw"
      },
      "source": [
        "#Plot government published poverty rates against predicted poverty rates\n",
        "\n",
        "plot_filename = \"-\".join([\"CNN\", \"PLOT\", \"RES34\", country, year, day_sat, str(img_res), \"validation\"]) + \".eps\"\n",
        "\n",
        "col_dict = {True: \"r\", False:\"b\"}\n",
        "col = [col_dict[valid] for valid in avg_features_full[\"data_split\"] == (validation_size_percent/100)]\n",
        "\n",
        "plt.scatter(y_full, best_ridge.predict(Xs_full), c = col)\n",
        "plt.ylabel(\"Predictions\")\n",
        "plt.xlabel(\"Survey\")\n",
        "plt.suptitle(country+ \" \" + year+ \" \" + \"Ridge Regression\")\n",
        "txt = \"\"\n",
        "plt.figtext(0.5, -0.1, txt, wrap=True, horizontalalignment=\"center\", fonsize=12)\n",
        "abline(1,0)\n",
        "\n",
        "plt.savefig(plot_filename, format=\"eps\", dpi = 600)\n",
        "shutil.copy(os.path.join(\"/content/\", plot_filename, \"/content/gdrive/MyDrive\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIfjj1DH2v2U"
      },
      "source": [
        "#Exports ridge regression model to GDrive\n",
        "import pickls\n",
        "trained_ridge_regression_file = \"_\".join([\"CNN\", \"RidgeModel\",\"RES34\", country, year, day_sat, str(img_res)]) +\".pkl\"\n",
        "\n",
        "#Save file to current WD\n",
        "with open(trained_ridge_regression_file, \"wb\") as file: \n",
        "  pickle.dump(best_ridge, file)\n",
        "\n",
        "#copy to gdrive\n",
        "shutil.copy(os.path.join(\"/content/\", trained_ridge_regression_file), \"/content/gdrive/MyDrive/\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oevj-Hun3UbF"
      },
      "source": [
        "#Load from file\n",
        "with open(trained_ridge_regression_file, \"rb\") as file: \n",
        "  best_ridge = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTd8Kxkk4LtG"
      },
      "source": [
        "#Extract array of image level features, collapse into 1D array to get predicted poverty rates\n",
        "\n",
        "#Perform prediction for all grids\n",
        "pred_out = best_ridge.predict(features_raw.loc[ : , \"0\":\"511\"])\n",
        "#Make prediction a DF with corresponding imagery filename as index\n",
        "pred_out_pd = pd.DataFrame({'prediction': pred_out.flatten()}, index = features_raw.filename)\n",
        "\n",
        "print(len(pred_out))\n",
        "print(len(features_raw.filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD-NrwUW4yXS"
      },
      "source": [
        "#Merge poverty prediction dataframe with data frame containing gov-published poverty rates using imagery filename as merging partner\n",
        "print(df.shape)\n",
        "output = df_raw.join(pred_out_pd, on = \"filename\", how = \"outer\")\n",
        "print(output.shape)\n",
        "\n",
        "print(\"---------\")\n",
        "print(output[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xByr5cKI5G6k"
      },
      "source": [
        "#Generate poverty prediction output file as CSV file\n",
        "poverty_prediction_file = \"_\".join([\"CNN\", \"POV\", \"RES34\", country, year, day_dat, str(img_res)] )+\".csv\"\n",
        "output.to_csv(poverty_prediction_file)\n",
        "\n",
        "shutil.copy(os.path.join(\"/content/\",poverty_prediction_file), \"/content/gDrive/MyDrive/\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}